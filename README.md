# Llama3 on Mobile
This repository is an implementation of converting the Llama3-8B-Instruct model weights and deploying it on Android for on-device inference.

## Pipeline:
<img src="https://github.com/NSTiwari/Llama3-on-Mobile/blob/main/mobile-llama3-pipeline.png"/>

# Demo Output:
<img src="https://github.com/NSTiwari/Llama3-on-Mobile/blob/main/mobilellama3.gif"/>



## Citation

```bibtex
@software{mlc-llm,
    author = {MLC team},
    title = {{MLC-LLM}},
    url = {https://github.com/mlc-ai/mlc-llm},
    year = {2023}
}
```
