# MobileLlama3: Llama3 on Mobile
This repository is an implementation of quantizing and converting the Llama3-8B-Instruct model weights and deploying it on Android for on-device inference

<img src="https://github.com/NSTiwari/Llama3-on-Mobile/blob/main/llama3_icon.png" width="250" height="250"/>

## Pipeline:
<img src="https://github.com/NSTiwari/Llama3-on-Mobile/blob/main/mobile-llama3-pipeline.png"/>

## Demo Output:
<img src="https://github.com/NSTiwari/Llama3-on-Mobile/blob/main/mobilellama3.gif"/>

## Resources:

1. [Colab notebook to quantize and convert Llama3-8B-Instruct model](https://github.com/NSTiwari/Llama3-on-Mobile/blob/main/Llama3_on_Mobile.ipynb)
2. [HuggingFace repository](https://huggingface.co/NSTiwari/Llama-3-8B-q4f16_1-android) for Llama3-8B-Instruct converted weights.
3. [Medium blog](https://tiwarinitin1999.medium.com/ml-story-mobilellama3-run-llama3-locally-on-mobile-36182fed3889) for step-by-step implementation to deploy Llama-3-8B-Instruct on Android.
4. [Medium blog](https://tiwarinitin1999.medium.com/set-up-android-studio-on-gcp-vm-instance-81081febb071) to set up environment on Google Cloud Platform VM instance.
5. Install the [APK](https://github.com/NSTiwari/Llama3-on-Mobile/blob/main/mobilellama3.apk) directly.


## Citation

```bibtex
@software{mlc-llm,
    author = {MLC team},
    title = {{MLC-LLM}},
    url = {https://github.com/mlc-ai/mlc-llm},
    year = {2023}
}
```
