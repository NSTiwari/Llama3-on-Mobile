# Llama3 on Mobile
This repository is an implementation of converting the Llama3-8B-Instruct model weights and deploying it on Android for on-device inference.

## Pipeline:
<img src="https://github.com/NSTiwari/Llama3-on-Mobile/blob/main/mobile-llama3-pipeline.png"/>

# Demo Output:
<img src="https://github.com/NSTiwari/Llama3-on-Mobile/blob/main/mobilellama3.gif"/>

## Resources:

1. [Colab notebook to quantize and convert Llama3-8B-Instruct model](https://github.com/NSTiwari/Llama3-on-Mobile/blob/main/Llama3_on_Mobile.ipynb)
2. [Medium blog]() for step-by-step implementation to deploy Llama-3-8B-Instruct on Android.
3. [Medium blog]() to set up environment on Google Cloud Platform VM instance.
4. Install the [APK]() directly.


## Citation

```bibtex
@software{mlc-llm,
    author = {MLC team},
    title = {{MLC-LLM}},
    url = {https://github.com/mlc-ai/mlc-llm},
    year = {2023}
}
```
